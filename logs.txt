Dataset already exists. Skipping download.

journey to a patient (for I had now returned to civil practice), when
my way led me through Baker Street. As I passed the well-remembered
door, which must always be associated in my mind with my wooing, and
with the dark incidents of the Study in Sc
... excerpt from training data.
vocab_size: 98
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:16<?, ?it/s]
Batch 0 loss = 4.6248
Traceback (most recent call last):
  File "/home/aiscuser/Play/llm.py", line 308, in <module>
    main()
  File "/home/aiscuser/Play/llm.py", line 285, in main
    train(model, dataloader, optimizer, device, epochs = 1)
  File "/home/aiscuser/Play/llm.py", line 264, in train
    loss.backward()
  File "/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/opt/conda/envs/ptca/lib/python3.9/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
